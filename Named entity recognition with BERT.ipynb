{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install seqeval","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting seqeval\n  Downloading seqeval-0.0.12.tar.gz (21 kB)\nRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.7/site-packages (from seqeval) (1.18.1)\nRequirement already satisfied: Keras>=2.2.4 in /opt/conda/lib/python3.7/site-packages (from seqeval) (2.3.1)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (2.10.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (5.3)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (1.4.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (1.0.8)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (1.1.0)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from Keras>=2.2.4->seqeval) (1.14.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7423 sha256=e5a787143ba4923f984c9b335c186fd3208040ad46850b8e6f490878858a43da\n  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-0.0.12\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport torch\nimport transformers\n\nimport numpy as np \nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\n\nfrom tqdm import tqdm, trange\nfrom seqeval.metrics import classification_report, f1_score\nfrom transformers import BertTokenizer, BertConfig\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.sequence import pad_sequences\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertForTokenClassification, AdamW, get_linear_schedule_with_warmup ","execution_count":28,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"base_path = \"/kaggle\"\n\n# Chech if it's in kaggle environment \nif os.path.exists(base_path):\n    input_path = os.path.join(base_path, \"input\", \"entity-annotated-corpus\")\n    output_path = os.path.join(base_path, \"working\")\nelse:\n    base_path = \"data\"\n    input_path = base_path\n    output_path = os.path.join(base_path, \"submissions\")\n\n\nner_dataset = os.path.join(input_path, \"ner_dataset.csv\")\nner = os.path.join(input_path, \"ner.csv\")","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(ner_dataset, encoding=\"latin1\")","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"    Sentence #           Word  POS    Tag\n0  Sentence: 1      Thousands  NNS      O\n1          NaN             of   IN      O\n2          NaN  demonstrators  NNS      O\n3          NaN           have  VBP      O\n4          NaN        marched  VBN      O\n5          NaN        through   IN      O\n6          NaN         London  NNP  B-geo\n7          NaN             to   TO      O\n8          NaN        protest   VB      O\n9          NaN            the   DT      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>NaN</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>NaN</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>NaN</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>NaN</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>NaN</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Data analysis and Data cleaning"},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Sentence #\"].fillna(method=\"ffill\", inplace=True)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"    Sentence #           Word  POS    Tag\n0  Sentence: 1      Thousands  NNS      O\n1  Sentence: 1             of   IN      O\n2  Sentence: 1  demonstrators  NNS      O\n3  Sentence: 1           have  VBP      O\n4  Sentence: 1        marched  VBN      O\n5  Sentence: 1        through   IN      O\n6  Sentence: 1         London  NNP  B-geo\n7  Sentence: 1             to   TO      O\n8  Sentence: 1        protest   VB      O\n9  Sentence: 1            the   DT      O","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sentence #</th>\n      <th>Word</th>\n      <th>POS</th>\n      <th>Tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sentence: 1</td>\n      <td>Thousands</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sentence: 1</td>\n      <td>of</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sentence: 1</td>\n      <td>demonstrators</td>\n      <td>NNS</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sentence: 1</td>\n      <td>have</td>\n      <td>VBP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sentence: 1</td>\n      <td>marched</td>\n      <td>VBN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Sentence: 1</td>\n      <td>through</td>\n      <td>IN</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Sentence: 1</td>\n      <td>London</td>\n      <td>NNP</td>\n      <td>B-geo</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Sentence: 1</td>\n      <td>to</td>\n      <td>TO</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Sentence: 1</td>\n      <td>protest</td>\n      <td>VB</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Sentence: 1</td>\n      <td>the</td>\n      <td>DT</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_list = list(set(df[\"Word\"].values))\n\nprint(f\"There are {len(words_list)} words.\")\n\nwords_list[:10]","execution_count":8,"outputs":[{"output_type":"stream","text":"There are 35178 words.\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"['10-man',\n 'reorganization',\n 'establishments',\n 'Recording',\n 'nook',\n 'blackout',\n 'depleting',\n 'welcomes',\n 'Endeavor',\n 'Kanow']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_values = list(set(df[\"Tag\"].values))\ntags_values.append(\"PAD\")\n\ntag2idx = {t: i for i, t in enumerate(tags_values)}","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare dataset as BERT input"},{"metadata":{"trusted":true},"cell_type":"code","source":"class SentenceGetter():\n    def __init__(self, data):\n        self.data = data\n        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n                                                           s[\"POS\"].values.tolist(),\n                                                           s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n        \n        self._split_sentence_and_labels()\n        \n    def _split_sentence_and_labels(self):\n        self.sentences = []\n        self.labels = []\n        for sentence in self.grouped:\n            tmp_sentence, tmp_tag = [], []\n            for word, _, tag in sentence:\n                tmp_sentence.append(word)\n                tmp_tag.append(tag)\n\n            self.sentences.append(tmp_sentence)\n            self.labels.append(tmp_tag)","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenize_and_preserve_labels(sentence, text_labels):\n    tokenized_sentence = []\n    sentence_labels = []\n    for word, label in zip(sentence, text_labels):\n        # Tokenize the word and count # of subwords the word is broken into\n        tokenized_word = tokenizer.tokenize(word)\n        n_subwords = len(tokenized_word)\n\n        # Add the tokenized word to the final tokenized word list\n        tokenized_sentence.extend(tokenized_word)\n\n        # Add the same label to the new list of labels `n_subwords` times\n        sentence_labels.extend([label] * n_subwords)\n    \n    return tokenized_sentence, sentence_labels","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataSet():\n    def __init__(self, sentence_getter, tokenizer, max_len, tag2idx):\n        # Tokenize sentences\n        self.tokens = []\n        self.labels = []\n        for sentences, labels in zip(sentence_getter.sentences, sentence_getter.labels):\n            tok, lab = tokenize_and_preserve_labels(sentences, labels)\n            \n            self.tokens.append([\"[CLS]\"] + tok)\n            self.labels.append([\"O\"] + lab)\n        \n        # Convert tokens to ids\n        self.input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in self.tokens], \n                                       maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n        \n        # Convert tags to ids\n        self.tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in self.labels], maxlen=max_len, \n                                  value=tag2idx[\"PAD\"], padding=\"post\", dtype=\"long\", truncating=\"post\")\n        \n        pad_tok = tokenizer.vocab[\"[PAD]\"]\n        sep_tok = tokenizer.vocab[\"[SEP]\"]\n        o_lab = tag2idx[\"O\"]\n        # Adding [SEP] and O for mark the end of sentence or nothing for splited sentences\n        for voc_ids, tag_ids in zip(self.input_ids, self.tags):\n            if voc_ids[-1] == pad_tok:\n                continue\n            else:\n                voc_ids[-1] = sep_tok\n                tag_ids[-1] = o_lab\n\n        # Place a mask (zero) over the padding tokens\n        self.attention_masks = [[float(i != 0.0) for i in ii] for ii in self.input_ids]","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Download BERT tokenizer"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)","execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descriptiâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25ae92b1192d4823a4a000dc449c92df"}},"metadata":{}},{"output_type":"stream","text":"\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentence_getter = SentenceGetter(df)\ndataset = DataSet(sentence_getter, tokenizer, 32, tag2idx)","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Split data into train and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(dataset.input_ids, dataset.tags,\n                                                            random_state=2018, test_size=0.1)\n\ntr_masks, val_masks, _, _ = train_test_split(dataset.attention_masks, dataset.input_ids,\n                                             random_state=2018, test_size=0.1)","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_inputs = torch.tensor(tr_inputs)\nval_inputs = torch.tensor(val_inputs)\n\ntr_tags = torch.tensor(tr_tags)\nval_tags = torch.tensor(val_tags)\n\ntr_masks = torch.tensor(tr_masks)\nval_masks = torch.tensor(val_masks)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\n\ntrain_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\nvalid_data = TensorDataset(val_inputs, val_masks, val_tags)\nvalid_sampler = SequentialSampler(valid_data)\nvalid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_size)","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Donwload pre-trained BERT model"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BertForTokenClassification.from_pretrained(\n    \"bert-base-cased\",\n    num_labels=len(tag2idx),\n    output_attentions=False,\n    output_hidden_states=False\n)","execution_count":70,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.cuda()","execution_count":71,"outputs":[{"output_type":"execute_result","execution_count":71,"data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (1): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (2): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (3): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (4): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (5): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (6): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (7): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (8): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (9): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (10): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (11): BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=18, bias=True)\n)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Model fine-tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"full_finetuning = True\nif full_finetuning:\n    param_optimizer = list(model.named_parameters())\n    no_decay = ['bias', 'gamma', 'beta']\n    optimizer_grouped_parameters = [\n        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.01},\n        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n         'weight_decay_rate': 0.0}\n    ]\nelse:\n    param_optimizer = list(model.classifier.named_parameters())\n    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\noptimizer = AdamW(\n    optimizer_grouped_parameters,\n    lr=3e-5,\n    eps=1e-8\n)","execution_count":72,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Create the learning rate scheduler."},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 3\nmax_grad_norm = 1.0\n\n# Total number of training steps is number of batches * number of epochs.\ntotal_steps = len(train_dataloader) * epochs\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=0,\n    num_training_steps=total_steps\n)","execution_count":58,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Training and validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=2).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","execution_count":69,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_values, validation_loss_values = [], []\n\nfor _ in trange(epochs, desc=\"Epoch\"):\n    # ========================================\n    #               Training\n    # ========================================\n    model.train()\n    \n    total_loss = 0\n    for step, batch in enumerate(train_dataloader):\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        \n        # Clear previously gradients.\n        model.zero_grad()\n        \n        # forward pass\n        outputs = model(b_input_ids, token_type_ids=None,\n                        attention_mask=b_input_mask, labels=b_labels)\n        loss = outputs[0]\n        \n        # Perform a backward pass to calculate the gradients.\n        loss.backward()\n        \n        total_loss += loss.item()\n        # Clip the norm of the gradient (for prevent \"exploding gradients\")\n        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n        \n        # Update parameters\n        optimizer.step()\n        \n        # Update the learning rate.\n        scheduler.step()\n\n    # Calculate the average loss over the training data.\n    avg_train_loss = total_loss / len(train_dataloader)\n    print(\"Average train loss: {}\".format(avg_train_loss))\n\n    loss_values.append(avg_train_loss)\n    \n    # ========================================\n    #               Validation\n    # ========================================\n    model.eval()\n    \n    eval_loss, eval_accuracy = 0, 0\n    nb_eval_steps, nb_eval_examples = 0, 0\n    predictions , true_labels = [], []\n    for batch in valid_dataloader:\n        batch = tuple(t.to(device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n\n        # Not to compute or store gradients,\n        with torch.no_grad():\n            # Forward pass.\n            outputs = model(b_input_ids, token_type_ids=None,\n                            attention_mask=b_input_mask, labels=b_labels)\n        \n        # Move logits and labels to CPU\n        logits = outputs[1].detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n\n        # Calculate the accuracy for this batch.\n        eval_loss += outputs[0].mean().item()\n        eval_accuracy += flat_accuracy(logits, label_ids)\n        \n        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n        true_labels.extend(label_ids)\n\n        nb_eval_examples += b_input_ids.size(0)\n        nb_eval_steps += 1\n\n    # Compute statistics\n    eval_loss = eval_loss / nb_eval_steps\n    validation_loss_values.append(eval_loss)\n    \n    pred_tags = [tags_values[p_i] for p, l in zip(predictions, true_labels)\n                                 for p_i, l_i in zip(p, l) if tags_values[l_i] != \"PAD\"]\n    valid_tags = [tags_values[l_i] for l in true_labels\n                                  for l_i in l if tags_values[l_i] != \"PAD\"]\n    \n    # Show values\n    print(f\"Validation loss: {eval_loss}\")\n    print(f\"Validation Accuracy: {eval_accuracy / nb_eval_steps}\")\n    print(f\"Classification report {classification_report(valid_tags, pred_tags)}\")\n    print(f\"Validation F1-Score: {f1_score(pred_tags, valid_tags)}\")","execution_count":68,"outputs":[{"output_type":"stream","text":"\n\n\n\nEpoch:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A","name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-68-bb11db91ed28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Perform a backward pass to calculate the gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Compute train loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = os.path.join(output_path, \"trained_bert.pt\")\ntorch.save(model.state_dict(), model_path)","execution_count":43,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot learning curve"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(training_loss, validation_loss):\n    plt.figure(figsize=(12, 8))\n    \n    plt.plot(training_loss, 'b-o', label=\"training loss\")\n    plt.plot(validation_loss, 'r-o', label=\"validation loss\")\n\n    plt.title(\"Learning curve\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Loss\")\n    plt.legend()\n    plt.show()","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(loss_values, validation_loss_values)","execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 864x576 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def prediction(sentence):\n    tokenized_sentence = tokenizer.encode(sentence)\n    input_ids = torch.tensor([tokenized_sentence]).cuda()\n\n    with torch.no_grad():\n        output = model(input_ids)\n    label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)\n\n    tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n    new_tokens, new_labels = [], []\n    for token, label_idx in zip(tokens, label_indices[0]):\n        if token.startswith(\"##\"):\n            new_tokens[-1] = new_tokens[-1] + token[2:]\n        else:\n            new_labels.append(tags_values[label_idx])\n            new_tokens.append(token)\n   \n    for token, label in zip(new_tokens, new_labels):\n        print(\"{}\\t{}\".format(label, token))","execution_count":46,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentence = \"\"\"\nMr. Trumpâ€™s tweets began just moments after a Fox News report by Mike Tobin, a \nreporter for the network, about protests in Minnesota and elsewhere.\"\"\"\n\nprediction(test_sentence)","execution_count":47,"outputs":[{"output_type":"stream","text":"O\t[CLS]\nB-per\tMr\nB-per\t.\nI-per\tTrump\nO\tâ€™\nO\ts\nO\ttweets\nO\tbegan\nO\tjust\nO\tmoments\nO\tafter\nO\ta\nB-org\tFox\nI-org\tNews\nO\treport\nO\tby\nB-per\tMike\nI-per\tTobin\nO\t,\nO\ta\nO\treporter\nO\tfor\nO\tthe\nO\tnetwork\nO\t,\nO\tabout\nO\tprotests\nO\tin\nB-geo\tMinnesota\nO\tand\nO\telsewhere\nO\t.\nO\t[SEP]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentence = \"\"\"\nThe New York Times (sometimes abbreviated as the NYT and NYTimes) is an American newspaper based in New York City with worldwide \ninfluence and readership.[6][7][8] Founded in 1851, the paper has won 130 Pulitzer Prizes, more than any other newspaper.\"\"\"\n\nprediction(test_sentence)","execution_count":48,"outputs":[{"output_type":"stream","text":"O\t[CLS]\nO\tThe\nB-org\tNew\nI-org\tYork\nI-org\tTimes\nO\t(\nO\tsometimes\nO\tabbreviated\nO\tas\nO\tthe\nB-org\tNYT\nO\tand\nB-org\tNYTimes\nO\t)\nO\tis\nO\tan\nB-gpe\tAmerican\nO\tnewspaper\nO\tbased\nO\tin\nB-geo\tNew\nI-geo\tYork\nI-geo\tCity\nO\twith\nO\tworldwide\nO\tinfluence\nO\tand\nO\treadership\nO\t.\nO\t[\nO\t6\nO\t]\nO\t[\nO\t7\nO\t]\nO\t[\nO\t8\nO\t]\nO\tFounded\nO\tin\nB-tim\t1851\nO\t,\nO\tthe\nO\tpaper\nO\thas\nO\twon\nO\t130\nB-org\tPulitzer\nI-org\tPrizes\nO\t,\nO\tmore\nO\tthan\nO\tany\nO\tother\nO\tnewspaper\nO\t.\nO\t[SEP]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentence = \"UK Prime Minister Boris Johnson is expected to explain any changes to lockdown measures and launch a threat level alert system.\"\n\nprediction(test_sentence)","execution_count":49,"outputs":[{"output_type":"stream","text":"O\t[CLS]\nB-org\tUK\nB-per\tPrime\nI-per\tMinister\nI-per\tBoris\nI-per\tJohnson\nO\tis\nO\texpected\nO\tto\nO\texplain\nO\tany\nO\tchanges\nO\tto\nO\tlockdown\nO\tmeasures\nO\tand\nO\tlaunch\nO\ta\nO\tthreat\nO\tlevel\nO\talert\nO\tsystem\nO\t.\nO\t[SEP]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sentence = \"In South Korea, renewed restrictions are imposed after a series of transmissions linked to Seoul's leisure district.\"\n\nprediction(test_sentence)","execution_count":50,"outputs":[{"output_type":"stream","text":"O\t[CLS]\nO\tIn\nB-geo\tSouth\nI-geo\tKorea\nO\t,\nO\trenewed\nO\trestrictions\nO\tare\nO\timposed\nO\tafter\nO\ta\nO\tseries\nO\tof\nO\ttransmissions\nO\tlinked\nO\tto\nB-geo\tSeoul\nO\t'\nO\ts\nO\tleisure\nO\tdistrict\nO\t.\nO\t[SEP]\n","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}